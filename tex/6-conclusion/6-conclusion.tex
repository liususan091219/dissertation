%!TEX root =../../thesis-ex.tex

\chapter{Conclusion}
\label{ch6:conclusion}

In this thesis, we identify the general challenge of users' decision making on mobile devices. Different from decision makings on larger screen devices, users' decision making on mobile devices are more challenging because the ability for them to edit and navigate information is largely reduced. The decision support for mobile devices must leverage the context of mobile interface to generate solutions that users can easily use. As a result, we work on improving three important real-world problems on three systems that users frequently interact with in their daily life, making it more friendly to use on mobile devices:

$\bullet$ \textbf{Faceted Navigation in Shopping Search}. With reduced ability for keywords search, information systems provide more approaches for the user to navigate and explore the result space. Faceted navigation systems are frequently seen in today's mobile information systems, it is used in almost all shopping applications. By providing with users a ranked list of meta-data, faceted navigation systems allow users to easily navigate to options that otherwise would have been difficult for them to reach. In particular, we study the problem of recommending a list of $k$ numerical ranges so that users can: (1) navigate these ranges to more easily find the relevant product; (2) scan the ranges to get an idea of the distribution of the data. Novice users can benefit from (1) and (2) to improve the shopping experience. 

$\bullet$ \textbf{Mobile Permission Systems}. The decision on mobile devices is directly related to the users' information security. Under the General Data Protection Regulation (GDPR), ``\emph{consent must be freely given, specific, informed and ambiguous}''. Failing to satisfy requirements can result in millions of dollar in fine for a company. Our study, however, shows that a large number of Android applications had not provided sufficient explanations in the year of 2017. In particular, they tend to explain rarely used permissions much less than frequently used permissions. In addition, a part of the explanations under claim the privilege used by the application. As a result, we propose to assist application developers to explain the permissions to better assist users with decision making. 

$\bullet$ \textbf{Business Intelligence Systems}. With the business intelligence market growing fast right now, the natural language interface will benefit hundreds of millions of business users to conveniently conduct data analysts for making decisions. We find that by leveraging the database content, the state-of-the-art performance can increase about 4\%. 

\section{General Lessons Learned on Data-Driven Knowledge Support for User Decision Making}

This thesis works on improving three specific application problems on user decision making. Through this process, there are a few general lessons that can be learned based on the literature as well as our own exploration. 

$\bullet$ \textbf{Decision Support Relies on the Context}. Not all cases for decision supports are made equal. When the decision can be easily made, users may not need decision supports. When there exists a larger knowledge gap, the need for decision supports or explanation is higher than when the decision option is obvious. For example, if a GPS navigation app requests user location, it is easier to understand than when an alarm application requests the location. It would be reasonable to prioritize the explanation of the latter case. 

$\bullet$ \textbf{Using Similar Examples for Explanation}. It is a general strategy to explain things using similar examples. The logic behind this strategy seems to be that if many examples in the similar situation follow one pattern, it must be more or less correct to do so. This strategy is similar to the ``\emph{people who bought this also bought}'' in product recommendation, where by leveraging similar products, it is possible to discover items that the user potentially will be interested in. The similar idea is seen in LIME, where the system leverages nearest neighbors and a linear classifier to explain the decisions made by a complicated model. 

$\bullet$ \textbf{Is Convincing Always a Good Thing?} Our CLAP model was initially designed to assist users to understand permission purposes when the explanation is not present. However, later we found that such approach might be very dangerous: if the explanation is incorrect, however the user believes in it and grant the permission, such operation may be dangerous. As a result, we propose to use the system to support expert (application developers) instead of users, although this will not solve the problem if a developer does not check the results and directly adopt the case. In general, decision support systems must reason about the potential harm if the knowledge being suggested is wrong. 

\section{Extension of Current Work}

\subsection{Assisting Shopping Decisions}

As an e-Commerce business/catalog grows larger, user exploration also becomes more difficult: a majority of Walmart's catalog have never been purchased or viewed before. When the search engine uses machine learning to train its ranking algorithm, the ranking becomes even more biased towards the most popular items and user exploration becomes even harder, which leads to suboptimal decisions. How to assist users to more thoroughly explore the information space while reducing their efforts in this process? For this problem, we plan to study an intelligent-agent approach. The agent explicitly queries the user's decision rules: (1) the agent pro-actively asks questions on the facets to learn the user's preference; (2) the agent crawls text data from multiple resources (e.g., user reviews) to support the user's decision choices; (3) the agent explains decision rules using an economic model, e.g., ``would you pay 50\$ more to get a cashmere sweater?''. By explicitly modeling the user's decision rules, the agent can better understand the user's need and help the user explore less popular items which are potentially the optimal options. 

\subsection{Assisting Security Decision Making}
\label{sec:mobile_future}

The problem of assisting users' security decision making can be generalized: if the user have to make a decision out of an unknown situation where the user does not have know the implementation of a program, and yet the decision would have effect on the user's own benefit, e.g., loss of security or money, how can we help the user decide? What explanations would be more convincing? If an explanation is convincing but not telling the truth, would the user falsely believe in it? In other words, does it work better to rely on the users themselves to justify the decision with the system providing some tools to support (e.g., the user can ask questions), or does it work better if the system provides the full information and the user may just adopt?  

\subsection{Assisting Natural Language Interface}

The existing datasets on NL2SQL are mostly perfectly aligned. That is, for a large part of the dataset, both Hypothesis 1 and Hypothesis 2 in Section 5 are correct. Even if the vocabulary cannot fully match, the gap is relatively small. On the other hand, real-world NL2SQL requires more understanding. For example, if the questions asks \texttt{what are the price of luxury cars?} It requires NLI to understand the meaning of the word \emph{luxury} which is not easy. If a dataset is naturally formed, for example, consider the question and SQL pair found on Stack Overflow or GitHub, the larger gap will exist due to the knowledge gap between the question asker and question answerer. For example, one of them may be an expert and the other one may be a novice. In this case, would translation-based retrieval helps like it does in the community question answer retrieval problem (Section~\ref{sec:cqa})? What would be the most effective way of training a robust model from large but noisy datasets? 

\section{Future Work on Data-Driven Decision Support}

\subsection{Supporting Peer Review Decision Making}

As the scale of many AI conferences increase dramatically, there is an urgent need of peer reviewers. However, the reviewer does not increase with the same scale. In AI community, there is an urgent need for supporting the peer reviewing jobs of reviewers and meta-reviewers. With the OpenReview platform, there has been more and more professional peer review data accumulating every year, e.g., there has been 9K individual reviews for the ICLR conference. Such data provides an opportunity for studying automatic decision making on peer reviews. 

Similarity and difference with existing review datasets: the structure of the dataset is very similar to existing review datasets, e.g., hotel review data, because each review often discuss pros and cons of the paper, and the rating for one paper should also depend on the individual aspect rating. However, each paper is given only 3-5 reviews, while in hotel reviews each entity has thousands of reviews. With the limited number of reviews, it is less efficient to discover truth in an unsupervised manner. Further more, it would be more challenging to leverage collaborative ideas. For example, can we suggest a sentence for the reviewer to adopt? If we select candidate sentences from the paper that looks most similar to current work, it will fail because these similar papers are similar only in the topic, for examples, if all the existing papers on the topic data-driven decision support on mobile devices were rejected, it does not justify that the current paper should be rejected. As a result, the decision support task would be more challenging. 

\subsection{Supporting Developer Search on Stack Overflow}
\label{sec:cqa}

Stack Overflow is the largest development question answering website. It has millions of monthly traffic, and is used by users across the worlds. Despite the large traffic, the new answer count on StackOverflow is decreasing. To assist new question asker on Stack Overflow, it is an important task to link question to other questions. StackOverflow itself also have a large number of links extracted from the links in answers and questions to other questions. Such links create an opportunity for studying the problem of recommending similar questions to Stack Overflow users. 

It is, however, difficult to match the semantic relatedness between two questions. The main difficulty comes from developers' knowledge gap in asking questions. For example, one novice user may ask ``how to connect two lists together'' while a more experienced user may use the word ``concatenate'' instead. The success of linking the two questions thus require the mapping between ``connect'' and concatenate. How to do the mapping? Existing work has used statistical machine translation to obtain the alignment matrix, so that the top ranked words for connect may contain the word concatenate. However, such matrix would be context free, and it is possible that connect does not translated to concatenate at all time. On the other hand, we have compared state-of-the-art performance of translation based retrieval model with semantic matching model using word embedding, where the word embedding is trained on the entire dataset. The result shows that semantic matching works better, but the representation is still not contextualized. It would be interesting to explore BERT on semantic matching, a similar task is recently explored in \cite{qiao2019understanding} and proved effective.